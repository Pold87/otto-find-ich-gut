{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import theano\n",
    "\n",
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    np.random.shuffle(X)\n",
    "    X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(labels).astype(np.int32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X, y, encoder, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test_data(path, scaler):\n",
    "    df = pd.read_csv(path)\n",
    "    df = df.iloc[:,:-1]\n",
    "    X = df.values.copy()\n",
    "    X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "    X = scaler.transform(X)\n",
    "    return X, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, encoder, scaler = load_train_data(\"../data/train80.csv\")\n",
    "X_test, ids = load_test_data('../data/holdout20.csv', scaler)\n",
    "num_classes = len(encoder.classes_)\n",
    "num_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjust network parameters over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = [w.get_value() for w in nn.get_all_params()]\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_weights_from(self.best_weights)\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers0 = [('input', InputLayer),\n",
    "           ('dropoutin', DropoutLayer),\n",
    "           ('dense0', DenseLayer),\n",
    "           ('dropout0', DropoutLayer),\n",
    "           ('dense1', DenseLayer),\n",
    "           ('dropout1', DropoutLayer),\n",
    "           ('dense2', DenseLayer),\n",
    "           ('output', DenseLayer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net0 = NeuralNet(layers=layers0,\n",
    "                 \n",
    "                 input_shape=(None, num_features),\n",
    "                 dropoutin_p = 0.0002,\n",
    "                 \n",
    "                 dense0_num_units=240,\n",
    "                 dropout0_p=0.235,\n",
    "                 \n",
    "                 dense1_num_units=510,\n",
    "                 dropout1_p=0.29,\n",
    "                 \n",
    "                 dense2_num_units=480,\n",
    "                 \n",
    "                 output_num_units=num_classes,\n",
    "                 output_nonlinearity=softmax,\n",
    "                 \n",
    "                 update=nesterov_momentum,                 \n",
    "                 \n",
    "                 update_learning_rate=theano.shared(float32(0.03)),\n",
    "                 update_momentum=theano.shared(float32(0.92)),\n",
    "\n",
    "                on_epoch_finished=[\n",
    "                    AdjustVariable('update_learning_rate', start=0.03, stop=0.001),\n",
    "                    AdjustVariable('update_momentum', start=0.92, stop=0.98),\n",
    "        ],\n",
    "                 \n",
    "                 eval_size=None,\n",
    "                 verbose=1,\n",
    "                 max_epochs=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InputLayer        \t(None, 93)          \tproduces      93 outputs\n",
      "  DropoutLayer      \t(None, 93)          \tproduces      93 outputs\n",
      "  DenseLayer        \t(None, 240)         \tproduces     240 outputs\n",
      "  DropoutLayer      \t(None, 240)         \tproduces     240 outputs\n",
      "  DenseLayer        \t(None, 510)         \tproduces     510 outputs\n",
      "  DropoutLayer      \t(None, 510)         \tproduces     510 outputs\n",
      "  DenseLayer        \t(None, 480)         \tproduces     480 outputs\n",
      "  DenseLayer        \t(None, 9)           \tproduces       9 outputs\n",
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------"
     ]
    }
   ],
   "source": [
    "net0.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample_sub = \"../submissions/sampleSubmission.csv\"\n",
    "sample_sub_df = pd.read_csv(sample_sub)\n",
    "\n",
    "def normalize(row, epsilon=1e-15):\n",
    "    \n",
    "    row = row / np.sum(row)\n",
    "    row = np.maximum(epsilon, row)\n",
    "    row = np.minimum(1 - epsilon, row)\n",
    "    \n",
    "    return row\n",
    "    \n",
    "def logloss_mc(y_true, y_probs):\n",
    "    \n",
    "    # Normalize probability data frame\n",
    "    y_probs = y_probs.apply(normalize, axis=1)\n",
    "        \n",
    "    log_vals = []\n",
    "        \n",
    "    for i, y in enumerate(y_true):\n",
    "        c = int(y.split(\"_\")[1])\n",
    "        log_vals.append(- np.log(y_probs.iloc[i,c - 1]))\n",
    "        \n",
    "    return np.mean(log_vals)\n",
    "\n",
    "df_holdout = pd.read_csv(\"../data/holdout20.csv\")\n",
    "y_valid = df_holdout.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_submission_fix(clf, X_test, ids, encoder, name='localcrosslasagne.csv'):\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    \n",
    "    with open(name, 'w') as f:\n",
    "        f.write('id,')\n",
    "        f.write(','.join(encoder.classes_))\n",
    "        f.write('\\n')\n",
    "        for id, probs in zip(ids, y_prob):\n",
    "            probas = ','.join([id] + map(str, probs.tolist()))\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "            \n",
    "    print(\"Wrote submission to file {}.\".format(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission to file localcrosslasagne.csv.\n"
     ]
    }
   ],
   "source": [
    "make_submission_fix(net0, X_test, ids, encoder)\n",
    "sub = pd.read_csv(\"localcrosslasagne.csv\").iloc[:, 1:]\n",
    "ll = logloss_mc(y_valid, sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49706260594221968"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ll"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
