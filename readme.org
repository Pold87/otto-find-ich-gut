* Overview

** Approach
- Use Lasagne, Keras, H20 and XGB to create an Ensemble classifier (average ensemble)

*** Files
- IPython_Crossvalidation: XGBoost (XGBoost in Python, using hyperopt)
- IPython: Otto_Group_Competition - REAL GOOD (lasagne, using hyperopt)
  
** Other stuff we've tried
- Ensemble classifier with voting
- Postprocessing smoother that finds optimal probability values
- A have hyperopt that find optimal hyperparameter values

** TODO:
- Include STD and M per row as feature
- Best submission:
  -- H20: h20newsubmission.csv (25 trials) (Script: otto-find-ich-gut/h2onew.R)
  -- XGB: xgboostpython_full_submission.csv (Script: IPython_Submissions/XGBoost.py)
  -- Keras: keras-otto-final.csv (Script: IPython_Submission/keras.py)
  -- Lasagne: lasagne-otto-final.csv (Script: IPython_Submissions/lasagne.ipynb)
