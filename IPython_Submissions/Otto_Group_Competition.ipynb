{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otto Group Product Classification Challenge using nolearn/lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short notebook is meant to help you getting started with nolearn and lasagne in order to train a neural net and make a submission to the Otto Group Product Classification Challenge.\n",
    "\n",
    "* [Otto Group Product Classification Challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge)\n",
    "* [Get the notebook from the Otto Group repository](https://github.com/ottogroup)\n",
    "* [Nolearn repository](https://github.com/dnouri/nolearn)\n",
    "* [Lasagne repository](https://github.com/benanne/Lasagne)\n",
    "* [A nolearn/lasagne tutorial for convolutional nets](http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne.layers import DenseLayer\n",
    "from lasagne.layers import InputLayer\n",
    "from lasagne.layers import DropoutLayer\n",
    "from lasagne.nonlinearities import softmax\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    np.random.shuffle(X)\n",
    "    X, labels = X[:, 1:-1].astype(np.float32), X[:, -1]\n",
    "    encoder = LabelEncoder()\n",
    "    y = encoder.fit_transform(labels).astype(np.int32)\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "    return X, y, encoder, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_test_data(path, scaler):\n",
    "    df = pd.read_csv(path)\n",
    "    X = df.values.copy()\n",
    "    X, ids = X[:, 1:].astype(np.float32), X[:, 0].astype(str)\n",
    "    X = scaler.transform(X)\n",
    "    return X, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_submission(clf, X_test, ids, encoder, name='lasagne-otto-final-25.csv'):\n",
    "    y_prob = clf.predict_proba(X_test)\n",
    "    with open(name, 'w') as f:\n",
    "        f.write('id,')\n",
    "        f.write(','.join(encoder.classes_))\n",
    "        f.write('\\n')\n",
    "        for id, probs in zip(ids, y_prob):\n",
    "            probas = ','.join([id] + map(str, probs.tolist()))\n",
    "            f.write(probas)\n",
    "            f.write('\\n')\n",
    "    print(\"Wrote submission to file {}.\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y, encoder, scaler = load_train_data('../data/train25.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_test, ids = load_test_data('../data/test25_no_classes.csv', scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_classes = len(encoder.classes_)\n",
    "num_features = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def float32(k):\n",
    "    return np.cast['float32'](k)\n",
    "\n",
    "class AdjustVariable(object):\n",
    "    def __init__(self, name, start=0.03, stop=0.001):\n",
    "        self.name = name\n",
    "        self.start, self.stop = start, stop\n",
    "        self.ls = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        if self.ls is None:\n",
    "            self.ls = np.linspace(self.start, self.stop, nn.max_epochs)\n",
    "\n",
    "        epoch = train_history[-1]['epoch']\n",
    "        new_value = float32(self.ls[epoch - 1])\n",
    "        getattr(nn, self.name).set_value(new_value)\n",
    "\n",
    "class EarlyStopping(object):\n",
    "    def __init__(self, patience=100):\n",
    "        self.patience = patience\n",
    "        self.best_valid = np.inf\n",
    "        self.best_valid_epoch = 0\n",
    "        self.best_weights = None\n",
    "\n",
    "    def __call__(self, nn, train_history):\n",
    "        current_valid = train_history[-1]['valid_loss']\n",
    "        current_epoch = train_history[-1]['epoch']\n",
    "        if current_valid < self.best_valid:\n",
    "            self.best_valid = current_valid\n",
    "            self.best_valid_epoch = current_epoch\n",
    "            self.best_weights = [w.get_value() for w in nn.get_all_params()]\n",
    "        elif self.best_valid_epoch + self.patience < current_epoch:\n",
    "            print(\"Early stopping.\")\n",
    "            print(\"Best valid loss was {:.6f} at epoch {}.\".format(\n",
    "                self.best_valid, self.best_valid_epoch))\n",
    "            nn.load_weights_from(self.best_weights)\n",
    "            raise StopIteration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers0 = [('input', InputLayer),\n",
    "           ('dropoutin', DropoutLayer),\n",
    "           ('dense0', DenseLayer),\n",
    "           ('dropout0', DropoutLayer),\n",
    "           ('dense1', DenseLayer),\n",
    "           ('dropout1', DropoutLayer),\n",
    "           ('dense2', DenseLayer),\n",
    "           ('output', DenseLayer)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net0 = NeuralNet(layers=layers0,\n",
    "                 \n",
    "                 input_shape=(None, num_features),\n",
    "                 dropoutin_p = 0.0002,\n",
    "                 \n",
    "                 dense0_num_units=1024,\n",
    "                 dropout0_p=0.235,\n",
    "                 \n",
    "                 dense1_num_units=512,\n",
    "                 dropout1_p=0.29,\n",
    "                 \n",
    "                 dense2_num_units=256,\n",
    "                 \n",
    "                 output_num_units=num_classes,\n",
    "                 output_nonlinearity=softmax,\n",
    "                 \n",
    "                 update=nesterov_momentum,                 \n",
    "                 \n",
    "                 update_learning_rate=theano.shared(float32(0.03)),\n",
    "                 update_momentum=theano.shared(float32(0.92)),\n",
    "\n",
    "                on_epoch_finished=[\n",
    "                    AdjustVariable('update_learning_rate', start=0.03, stop=0.0001),\n",
    "                    AdjustVariable('update_momentum', start=0.92, stop=0.98),\n",
    "        ],\n",
    "                 \n",
    "                 eval_size=None,\n",
    "                 verbose=1,\n",
    "                 max_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  InputLayer        \t(None, 93)          \tproduces      93 outputs\n",
      "  DropoutLayer      \t(None, 93)          \tproduces      93 outputs\n",
      "  DenseLayer        \t(None, 1024)        \tproduces    1024 outputs\n",
      "  DropoutLayer      \t(None, 1024)        \tproduces    1024 outputs\n",
      "  DenseLayer        \t(None, 512)         \tproduces     512 outputs\n",
      "  DropoutLayer      \t(None, 512)         \tproduces     512 outputs\n",
      "  DenseLayer        \t(None, 256)         \tproduces     256 outputs\n",
      "  DenseLayer        \t(None, 9)           \tproduces       9 outputs\n",
      "\n",
      " Epoch  |  Train loss  |  Valid loss  |  Train / Val  |  Valid acc  |  Dur\n",
      "--------|--------------|--------------|---------------|-------------|-------\n",
      "     1  |  \u001b[94m  0.965493\u001b[0m  |         nan  |          nan  |       nan%  |  3.8s\n",
      "     2  |  \u001b[94m  0.666625\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "     3  |  \u001b[94m  0.615967\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "     4  |  \u001b[94m  0.578388\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "     5  |  \u001b[94m  0.555945\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "     6  |  \u001b[94m  0.533545\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "     7  |  \u001b[94m  0.507595\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "     8  |  \u001b[94m  0.495492\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "     9  |  \u001b[94m  0.471952\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    10  |  \u001b[94m  0.464474\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    11  |  \u001b[94m  0.458277\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    12  |  \u001b[94m  0.433088\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    13  |  \u001b[94m  0.425331\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    14  |  \u001b[94m  0.405899\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    15  |  \u001b[94m  0.392338\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    16  |    0.392778  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    17  |  \u001b[94m  0.372776\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    18  |  \u001b[94m  0.364224\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    19  |  \u001b[94m  0.348801\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    20  |    0.350055  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    21  |  \u001b[94m  0.340305\u001b[0m  |         nan  |          nan  |       nan%  |  4.1s\n",
      "    22  |  \u001b[94m  0.334415\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    23  |  \u001b[94m  0.319076\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    24  |  \u001b[94m  0.313873\u001b[0m  |         nan  |          nan  |       nan%  |  4.1s\n",
      "    25  |  \u001b[94m  0.311945\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    26  |  \u001b[94m  0.295992\u001b[0m  |         nan  |          nan  |       nan%  |  4.1s\n",
      "    27  |  \u001b[94m  0.281999\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    28  |    0.285476  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    29  |  \u001b[94m  0.269212\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    30  |    0.270138  |         nan  |          nan  |       nan%  |  5.0s\n",
      "    31  |  \u001b[94m  0.263001\u001b[0m  |         nan  |          nan  |       nan%  |  3.8s\n",
      "    32  |  \u001b[94m  0.253786\u001b[0m  |         nan  |          nan  |       nan%  |  4.1s\n",
      "    33  |  \u001b[94m  0.251931\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    34  |    0.255194  |         nan  |          nan  |       nan%  |  4.3s\n",
      "    35  |  \u001b[94m  0.242082\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    36  |  \u001b[94m  0.225201\u001b[0m  |         nan  |          nan  |       nan%  |  3.8s\n",
      "    37  |  \u001b[94m  0.224167\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    38  |  \u001b[94m  0.220572\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    39  |  \u001b[94m  0.209264\u001b[0m  |         nan  |          nan  |       nan%  |  4.1s\n",
      "    40  |    0.217521  |         nan  |          nan  |       nan%  |  3.8s\n",
      "    41  |  \u001b[94m  0.198849\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    42  |  \u001b[94m  0.197897\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    43  |  \u001b[94m  0.195192\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    44  |  \u001b[94m  0.188594\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    45  |    0.194191  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    46  |    0.193059  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    47  |  \u001b[94m  0.181397\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    48  |  \u001b[94m  0.175381\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    49  |  \u001b[94m  0.175321\u001b[0m  |         nan  |          nan  |       nan%  |  4.0s\n",
      "    50  |  \u001b[94m  0.171255\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    51  |  \u001b[94m  0.164622\u001b[0m  |         nan  |          nan  |       nan%  |  3.8s\n",
      "    52  |  \u001b[94m  0.155546\u001b[0m  |         nan  |          nan  |       nan%  |  4.1s\n",
      "    53  |  \u001b[94m  0.152931\u001b[0m  |         nan  |          nan  |       nan%  |  4.3s\n",
      "    54  |  \u001b[94m  0.149046\u001b[0m  |         nan  |          nan  |       nan%  |  4.2s\n",
      "    55  |    0.158071  |         nan  |          nan  |       nan%  |  5.3s\n",
      "    56  |    0.150245  |         nan  |          nan  |       nan%  |  4.0s\n",
      "    57  |    0.159431  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    58  |  \u001b[94m  0.145853\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    59  |  \u001b[94m  0.139645\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    60  |    0.142805  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    61  |  \u001b[94m  0.137060\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    62  |  \u001b[94m  0.132346\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    63  |  \u001b[94m  0.124812\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    64  |  \u001b[94m  0.116812\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    65  |    0.117243  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    66  |    0.120013  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    67  |  \u001b[94m  0.110457\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    68  |  \u001b[94m  0.108301\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    69  |  \u001b[94m  0.102823\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    70  |    0.108831  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    71  |  \u001b[94m  0.100934\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    72  |    0.101673  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    73  |  \u001b[94m  0.100069\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    74  |  \u001b[94m  0.097451\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    75  |    0.100853  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    76  |  \u001b[94m  0.091748\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    77  |  \u001b[94m  0.088828\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    78  |  \u001b[94m  0.087706\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    79  |  \u001b[94m  0.080790\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    80  |  \u001b[94m  0.080674\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    81  |  \u001b[94m  0.080451\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    82  |    0.080472  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    83  |  \u001b[94m  0.079032\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    84  |  \u001b[94m  0.077196\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    85  |  \u001b[94m  0.070372\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    86  |  \u001b[94m  0.067077\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    87  |  \u001b[94m  0.062132\u001b[0m  |         nan  |          nan  |       nan%  |  4.0s\n",
      "    88  |  \u001b[94m  0.060489\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    89  |  \u001b[94m  0.058045\u001b[0m  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    90  |  \u001b[94m  0.055340\u001b[0m  |         nan  |          nan  |       nan%  |  4.0s\n",
      "    91  |  \u001b[94m  0.051317\u001b[0m  |         nan  |          nan  |       nan%  |  3.9s\n",
      "    92  |    0.051928  |         nan  |          nan  |       nan%  |  3.7s\n",
      "    93  |    0.054285  |         nan  |          nan  |       nan%  |  3.8s\n",
      "    94  |  \u001b[94m  0.046709\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    95  |  \u001b[94m  0.045069\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    96  |  \u001b[94m  0.044561\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    97  |  \u001b[94m  0.041186\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    98  |  \u001b[94m  0.040149\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "    99  |  \u001b[94m  0.038874\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n",
      "   100  |  \u001b[94m  0.037542\u001b[0m  |         nan  |          nan  |       nan%  |  3.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NeuralNet(X_tensor_type=<function matrix at 0x7fca0180e230>,\n",
       "     batch_iterator_test=<nolearn.lasagne.BatchIterator object at 0x7fc9f31b4890>,\n",
       "     batch_iterator_train=<nolearn.lasagne.BatchIterator object at 0x7fc9f31b4850>,\n",
       "     dense0_num_units=1024, dense1_num_units=512, dense2_num_units=256,\n",
       "     dropout0_p=0.235, dropout1_p=0.29, dropoutin_p=0.0002, eval_size=None,\n",
       "     input_shape=(None, 93),\n",
       "     layers=[('input', <class 'lasagne.layers.input.InputLayer'>), ('dropoutin', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense0', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout0', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense1', <class 'lasagne.layers.dense.DenseLayer'>), ('dropout1', <class 'lasagne.layers.noise.DropoutLayer'>), ('dense2', <class 'lasagne.layers.dense.DenseLayer'>), ('output', <class 'lasagne.layers.dense.DenseLayer'>)],\n",
       "     loss=<function negative_log_likelihood at 0x7fc9f35e7320>,\n",
       "     max_epochs=100, more_params={},\n",
       "     on_epoch_finished=[<__main__.AdjustVariable object at 0x7fc9f2ae96d0>, <__main__.AdjustVariable object at 0x7fc9f2ae9d10>],\n",
       "     on_training_finished=(),\n",
       "     output_nonlinearity=<theano.tensor.nnet.nnet.Softmax object at 0x7fca013dae50>,\n",
       "     output_num_units=9, regression=False,\n",
       "     update=<function nesterov_momentum at 0x7fc9f35e7500>,\n",
       "     update_learning_rate=<CudaNdarrayType(float32, scalar)>,\n",
       "     update_momentum=<CudaNdarrayType(float32, scalar)>,\n",
       "     use_label_encoder=False, verbose=1,\n",
       "     y_tensor_type=TensorType(int32, vector))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net0.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Submission File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote submission to file lasagne-otto-final-25.csv.\n"
     ]
    }
   ],
   "source": [
    "make_submission(net0, X_test, ids, encoder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
